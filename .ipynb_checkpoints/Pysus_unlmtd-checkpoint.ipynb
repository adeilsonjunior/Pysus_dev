{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed051e9-d502-489e-ba2a-518bd598af0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processo iniciado em: 2024-07-24 13:28:23.010772\n",
      "Dados já processados para MG-2023-01, pulando processamento.\n",
      "Dados já processados para MG-2023-02, pulando processamento.\n",
      "Baixando dados para MG-2023-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 176M/176M [00:00<00:00, 27.5GB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados baixados para MG-2023-03\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pysus.online_data.SIA import download\n",
    "import time\n",
    "from datetime import datetime\n",
    "import gc\n",
    "from retrying import retry\n",
    "\n",
    "# Lista de estados para o teste\n",
    "estados = ['MG', 'SP']\n",
    "ano = 2023\n",
    "meses = [str(month).zfill(2) for month in range(1, 13)]  # Todos os meses de 01 a 12\n",
    "grupos = ['PA']  # Grupo de procedimentos\n",
    "output_dir = 'dados_sia'  # Diretório para salvar arquivos de dados\n",
    "\n",
    "# Criar diretório de saída se não existir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Função para fazer o download com repetição em caso de falha\n",
    "@retry(wait_exponential_multiplier=1000, wait_exponential_max=10000, stop_max_attempt_number=5)\n",
    "def download_with_retry(estado, ano, meses, grupos):\n",
    "    return download(estado, str(ano), meses, grupos)\n",
    "\n",
    "# Gravar o horário inicial\n",
    "hora_inicio = datetime.now()\n",
    "print(f\"Processo iniciado em: {hora_inicio}\")\n",
    "\n",
    "# Função para processar e salvar dados de um estado e mês específico\n",
    "def process_and_save_data(estado, mes):\n",
    "    filename = f\"{output_dir}/{estado}_{ano}_{mes}.csv\"\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"Dados já baixados para {estado}-{ano}-{mes}, pulando download.\")\n",
    "        return pd.read_csv(filename)\n",
    "\n",
    "    print(f\"Baixando dados para {estado}-{ano}-{mes}\")\n",
    "    try:\n",
    "        data = download_with_retry(estado, str(ano), [mes], grupos)\n",
    "        print(f\"Dados baixados para {estado}-{ano}-{mes}\")\n",
    "        \n",
    "        try:\n",
    "            dfs = []\n",
    "            if isinstance(data, list):\n",
    "                for item in data:\n",
    "                    if hasattr(item, 'to_dataframe'):\n",
    "                        dfs.append(item.to_dataframe())\n",
    "                    elif hasattr(item, 'read_parquet'):\n",
    "                        dfs.append(item.read_parquet())\n",
    "                    else:\n",
    "                        print(f\"Objeto desconhecido: {type(item)}\")\n",
    "            elif hasattr(data, 'to_dataframe'):\n",
    "                dfs.append(data.to_dataframe())\n",
    "            elif hasattr(data, 'read_parquet'):\n",
    "                dfs.append(data.read_parquet())\n",
    "            else:\n",
    "                print(f\"Objeto ParquetSet não possui métodos conhecidos para leitura: {type(data)}\")\n",
    "                return None\n",
    "\n",
    "            if dfs:\n",
    "                df = pd.concat(dfs, ignore_index=True)\n",
    "                # Adicionar colunas ANO, MES e UF\n",
    "                df['ANO'] = ano\n",
    "                df['MES'] = mes\n",
    "                df['UF'] = estado\n",
    "\n",
    "                # Converter PA_VALAPR e PA_QTDAPR para float\n",
    "                df['PA_VALAPR'] = df['PA_VALAPR'].str.replace(',', '.').astype(float)\n",
    "                df['PA_QTDAPR'] = df['PA_QTDAPR'].astype(float)\n",
    "\n",
    "                # Selecionar as colunas desejadas\n",
    "                df = df[['ANO', 'MES', 'PA_UFMUN', 'PA_MUNPCN', 'PA_DOCORIG', 'PA_QTDAPR', 'PA_VALAPR', 'UF']]\n",
    "\n",
    "                # Salvar o DataFrame em CSV para evitar baixar novamente no futuro\n",
    "                df.to_csv(filename, index=False)\n",
    "                return df\n",
    "            else:\n",
    "                print(f\"Nenhum dado válido encontrado para {estado}-{ano}-{mes}\")\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar os dados para {estado}-{ano}-{mes}: {e}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao baixar dados para {estado}-{ano}-{mes}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Função para verificar e carregar dados previamente processados\n",
    "def load_previously_processed_data(output_dir):\n",
    "    processed_files = [f for f in os.listdir(output_dir) if f.endswith('.csv')]\n",
    "    return set((f.split('_')[0], f.split('_')[2].replace('.csv', '')) for f in processed_files)\n",
    "\n",
    "# Carregar dados previamente processados\n",
    "processed_data = load_previously_processed_data(output_dir)\n",
    "\n",
    "# Processar os dados para cada estado\n",
    "for estado in estados:\n",
    "    for mes in meses:\n",
    "        if (estado, mes) in processed_data:\n",
    "            print(f\"Dados já processados para {estado}-{ano}-{mes}, pulando processamento.\")\n",
    "            continue\n",
    "        \n",
    "        df = process_and_save_data(estado, mes)\n",
    "        if df is not None:\n",
    "            # Agrupar e salvar resultados intermediários por estado e mês\n",
    "            df_agrupado = df.groupby(['ANO', 'MES', 'PA_UFMUN', 'PA_MUNPCN', 'PA_DOCORIG', 'UF']).agg({\n",
    "                'PA_QTDAPR': 'sum',\n",
    "                'PA_VALAPR': 'sum'\n",
    "            }).reset_index()\n",
    "            df_agrupado.to_csv(f\"{output_dir}/{estado}_{ano}_{mes}_agrupado.csv\", index=False)\n",
    "            print(f\"Dados agrupados e salvos para {estado}-{ano}-{mes}\")\n",
    "\n",
    "        # Coletar lixo e liberar memória\n",
    "        gc.collect()\n",
    "        time.sleep(1)  # Esperar 1 segundo entre os downloads\n",
    "\n",
    "# Concatenar todos os arquivos agrupados por estado e mês\n",
    "dfs_final = []\n",
    "for estado in estados:\n",
    "    for mes in meses:\n",
    "        file_path = f\"{output_dir}/{estado}_{ano}_{mes}_agrupado.csv\"\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            dfs_final.append(df)\n",
    "\n",
    "# Exportar os dados finais\n",
    "if dfs_final:\n",
    "    df_final = pd.concat(dfs_final, ignore_index=True)\n",
    "    try:\n",
    "        df_final.to_excel('dados_agrupados.xlsx', index=False)\n",
    "        print(\"Dados exportados para 'dados_agrupados.xlsx' com sucesso.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Erro ao exportar para Excel: {e}. Exportando para CSV.\")\n",
    "        df_final.to_csv('dados_agrupados.csv', index=False)\n",
    "        print(\"Dados exportados para 'dados_agrupados.csv' com sucesso.\")\n",
    "\n",
    "# Gravar o horário final\n",
    "hora_fim = datetime.now()\n",
    "print(f\"Processo finalizado em: {hora_fim}\")\n",
    "\n",
    "# Calcular e exibir o tempo total do processo\n",
    "tempo_total = hora_fim - hora_inicio\n",
    "print(f\"Tempo total do processo: {tempo_total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36152d10-f6d0-463e-a420-594f8ed79d42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pysus_env)",
   "language": "python",
   "name": "pysus_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
